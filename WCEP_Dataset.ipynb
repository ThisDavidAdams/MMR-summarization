{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WCEP Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt2osxGf0uc0cWEEwKhf56",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThisDavidAdams/MMR-summarization/blob/main/WCEP_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqDTMVbHfaMr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md-7MpNJfWQG"
      },
      "source": [
        "!git clone https://github.com/gandharvsuri/wcep-mds-dataset\n",
        "%cd wcep-mds-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C_jntwefcYh"
      },
      "source": [
        "!pip install -r experiments/requirements.txt\n",
        "!python -m nltk.downloader punkt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lcyhMhkfgpo"
      },
      "source": [
        "!mkdir WCEP\n",
        "!gdown https://drive.google.com/uc?id=1qsd5pOCpeSXsaqNobXCrcAzhcjtG1wA1 -O WCEP/test.jsonl.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdqlH45ffkT7"
      },
      "source": [
        "import experiments.utils as utils\n",
        "\n",
        "test_data = list(utils.read_jsonl_gz('WCEP/test.jsonl.gz'))\n",
        "# partial_test_data = test_data[:10] # for experimenting\n",
        "print(\"Number of clusters:\",len(test_data))\n",
        "print(test_data[0].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km11eKhef0zq"
      },
      "source": [
        "!pip install gensim==3.8.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoc-EkIufvhk"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "import string \n",
        "\n",
        "doc2vec_model = Doc2Vec.load(\"/content/gdrive/MyDrive/ULETH/doc2vec/doc2vec.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbFweGsOgKGl"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    # Steps:\n",
        "    # 1. lowercase\n",
        "    # 2. Lemmatize. (It does not stem. Try to preserve structure not to overwrap with potential acronym).\n",
        "    # 3. Remove stop words.\n",
        "    # 4. Remove punctuations.\n",
        "    # 5. Remove character with the length size of 1.\n",
        "\n",
        "    lowered = str.lower(text)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(lowered)\n",
        "\n",
        "    words = []\n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            if w not in string.punctuation:\n",
        "                if len(w) > 1:\n",
        "                    lemmatized = lemmatizer.lemmatize(w)\n",
        "                    words.append(lemmatized)\n",
        "\n",
        "    return words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5upkrlxFgIJ2"
      },
      "source": [
        "def process_doc2vec_similarity(document, base_document):\n",
        "    # Both pretrained models are publicly available at public repo of jhlau.\n",
        "    # URL: https://github.com/jhlau/doc2vec\n",
        "\n",
        "    # Only handle words that appear in the doc2vec pretrained vectors.\n",
        "    # enwiki_dbow model contains 669549 vocabulary size.\n",
        "    tokens = preprocess(base_document)\n",
        "    tokens = list(filter(lambda x: x in doc2vec_model.wv.vocab.keys(), tokens))\n",
        "    base_vector = doc2vec_model.infer_vector(tokens)\n",
        "\n",
        "    tokens = preprocess(document)\n",
        "    tokens = list(filter(lambda x: x in doc2vec_model.wv.vocab.keys(), tokens))\n",
        "    vector = doc2vec_model.infer_vector(tokens)\n",
        "\n",
        "    scores = cosine_similarity([base_vector], [vector]).flatten()[0]\n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHdZ2MyJteQN"
      },
      "source": [
        "def compute_maximal_marginal_relevance(candidate_list, query, number_of_sentences=12, lambda_constant=0.75,\n",
        "                                       sim=process_doc2vec_similarity):\n",
        "    \"\"\"\n",
        "    hard coded to work for WCEP data\n",
        "    \"\"\"\n",
        "    # Find best sentence to start\n",
        "    initial_best_sentence = candidate_list[0]\n",
        "    prev = float(\"-inf\")\n",
        "\n",
        "    for article in candidate_list:\n",
        "        similarity = sim(article[\"text\"], query)\n",
        "        if similarity > prev:\n",
        "            initial_best_sentence = article\n",
        "            prev = similarity\n",
        "\n",
        "    try:\n",
        "        candidate_list.remove(initial_best_sentence)\n",
        "    except ValueError:\n",
        "        pass    # do nothing\n",
        "    sentences_to_return = [initial_best_sentence]\n",
        "\n",
        "    # Now find the prescribed number of best sentences\n",
        "    for i in range(1, number_of_sentences):\n",
        "        best_line = None\n",
        "        previous_marginal_relevance = float(\"-inf\")\n",
        "\n",
        "        for article in candidate_list:\n",
        "            # Calculate the Marginal Relevance\n",
        "            left_side = lambda_constant * sim(article[\"text\"], query)\n",
        "            right_values = [float(\"-inf\")]\n",
        "            for selected_sentence in sentences_to_return:\n",
        "                right_values.append((1 - lambda_constant) * sim(selected_sentence[\"text\"], article[\"text\"]))\n",
        "            right_side = max(right_values)\n",
        "            current_marginal_relevance = left_side - right_side\n",
        "\n",
        "            # Maximize Marginal Relevance\n",
        "            if current_marginal_relevance > previous_marginal_relevance:\n",
        "                previous_marginal_relevance = current_marginal_relevance\n",
        "                best_line = article\n",
        "        \n",
        "        if best_line is not None:\n",
        "          sentences_to_return += [best_line]\n",
        "          candidate_list.remove(best_line)\n",
        "\n",
        "    return sentences_to_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCVBlclflxh"
      },
      "source": [
        "from tqdm import tqdm\n",
        "test_data = test_data[:500]\n",
        "for c in tqdm(test_data):\n",
        "\n",
        "  base_doc = c[\"summary\"]\n",
        "\n",
        "  for a in c[\"articles\"]:\n",
        "    a[\"doc2vec_sim_score\"] = str(process_doc2vec_similarity(a[\"text\"], base_doc))\n",
        "  \n",
        "  c[\"articles\"] = sorted(c[\"articles\"], key=lambda a: float(a[\"doc2vec_sim_score\"]), reverse=True)[:30]\n",
        "  \n",
        "  c[\"articles\"] = compute_maximal_marginal_relevance(c[\"articles\"], base_doc)\n",
        "\n",
        "utils.write_jsonl(test_data, \"/content/gdrive/MyDrive/ULETH/test_data.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}